{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30355c6-69bc-4297-a03a-d4b275c481b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\jacks\\Downloads\\retail-chatter-research\\notebooks\n",
      "Files here: ['.ipynb_checkpoints', '01_reddit_auth_test.ipynb', '02_db_setup.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files here:\", os.listdir(\".\")[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d49a881-f84f-4253-99a6-1b921b07071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB created at: C:\\Users\\jacks\\Downloads\\retail-chatter-research\\data\\retail_chatter.db\n",
      "Tables: ['comments', 'posts', 'run_tickers', 'runs', 'sqlite_sequence', 'summaries']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# --- Find project root robustly ---\n",
    "# This notebook lives in: <root>/notebooks/02_db_setup.ipynb\n",
    "# So root is one level up from the notebook directory.\n",
    "NOTEBOOK_DIR = os.path.abspath(os.getcwd())\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\")) if NOTEBOOK_DIR.endswith(\"notebooks\") else NOTEBOOK_DIR\n",
    "\n",
    "DB_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
    "DB_PATH = os.path.join(DB_DIR, \"retail_chatter.db\")\n",
    "\n",
    "os.makedirs(DB_DIR, exist_ok=True)\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "conn.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "conn.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "\n",
    "schema_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS runs (\n",
    "  run_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  run_ts_utc TEXT NOT NULL,\n",
    "  window_hours INTEGER NOT NULL,\n",
    "  notes TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS run_tickers (\n",
    "  run_id INTEGER NOT NULL,\n",
    "  ticker TEXT NOT NULL,\n",
    "  PRIMARY KEY (run_id, ticker),\n",
    "  FOREIGN KEY (run_id) REFERENCES runs(run_id) ON DELETE CASCADE\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS posts (\n",
    "  post_id TEXT PRIMARY KEY,\n",
    "  ticker TEXT NOT NULL,\n",
    "  subreddit TEXT NOT NULL,\n",
    "  title TEXT,\n",
    "  selftext TEXT,\n",
    "  author TEXT,\n",
    "  url TEXT,\n",
    "  score INTEGER,\n",
    "  num_comments INTEGER,\n",
    "  created_utc INTEGER,\n",
    "  retrieved_utc INTEGER NOT NULL\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_posts_ticker_created ON posts (ticker, created_utc);\n",
    "CREATE INDEX IF NOT EXISTS idx_posts_subreddit_created ON posts (subreddit, created_utc);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS comments (\n",
    "  comment_id TEXT PRIMARY KEY,\n",
    "  post_id TEXT NOT NULL,\n",
    "  ticker TEXT NOT NULL,\n",
    "  subreddit TEXT NOT NULL,\n",
    "  parent_id TEXT,\n",
    "  author TEXT,\n",
    "  body TEXT,\n",
    "  score INTEGER,\n",
    "  created_utc INTEGER,\n",
    "  retrieved_utc INTEGER NOT NULL,\n",
    "  depth INTEGER DEFAULT 0,\n",
    "  FOREIGN KEY (post_id) REFERENCES posts(post_id) ON DELETE CASCADE\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_comments_ticker_created ON comments (ticker, created_utc);\n",
    "CREATE INDEX IF NOT EXISTS idx_comments_post ON comments (post_id);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS summaries (\n",
    "  run_id INTEGER NOT NULL,\n",
    "  ticker TEXT NOT NULL,\n",
    "  narrative TEXT,\n",
    "  themes_json TEXT,\n",
    "  stance_json TEXT,\n",
    "  created_utc INTEGER NOT NULL,\n",
    "  PRIMARY KEY (run_id, ticker),\n",
    "  FOREIGN KEY (run_id) REFERENCES runs(run_id) ON DELETE CASCADE\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "conn.executescript(schema_sql)\n",
    "conn.commit()\n",
    "\n",
    "tables = [r[0] for r in conn.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\")]\n",
    "print(\"DB created at:\", DB_PATH)\n",
    "print(\"Tables:\", tables)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287197e4-9348-466c-ad32-61b4ed53c512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted run_id: 1\n",
      "Tickers for run: [('NVDA',), ('TSLA',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3, time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "conn.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "\n",
    "run_ts = datetime.now(timezone.utc).isoformat()\n",
    "window_hours = 48\n",
    "\n",
    "conn.execute(\n",
    "    \"INSERT INTO runs (run_ts_utc, window_hours, notes) VALUES (?, ?, ?)\",\n",
    "    (run_ts, window_hours, \"schema test\")\n",
    ")\n",
    "run_id = conn.execute(\"SELECT last_insert_rowid()\").fetchone()[0]\n",
    "\n",
    "for t in [\"TSLA\", \"NVDA\"]:\n",
    "    conn.execute(\"INSERT OR IGNORE INTO run_tickers (run_id, ticker) VALUES (?, ?)\", (run_id, t))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "print(\"Inserted run_id:\", run_id)\n",
    "print(\"Tickers for run:\", conn.execute(\"SELECT ticker FROM run_tickers WHERE run_id=? ORDER BY ticker\", (run_id,)).fetchall())\n",
    "\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
